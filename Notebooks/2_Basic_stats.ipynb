{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c24614-bebf-4c01-8124-d450cdc53146",
   "metadata": {},
   "source": [
    "Basic stats Let's understand the dataset better\n",
    "\n",
    "## Choices in data cleaning and preprocessing\n",
    "\n",
    "### County Health Rankings Dataset\n",
    "The Health Dataset consists of 3193 rows and 250 columns. A row corresponds to a county in the US and the first columns consists of a FIPS code, the name of the state the county is within and the name of the county. The rest of the columns describe different health factors of each county such as obesity, smokers, alcoholism, education etc.\n",
    "\n",
    "226 of the rows in the data has an x in a column named \"Unreliable\". The column is not further explained in the data description given in the [PDF of data description](https://www.countyhealthrankings.org/sites/default/files/media/document/DataDictionary_2020_2.pdf) but for the sake of the column name, these rows will be removed. \n",
    "\n",
    "Due to the way pandas can read a csv, the first zero of the FIPS code can be automatically omitted. This will not allow `plotly` to plot those states, which is why we need to apply a zero infront of the row if the number is less than 5 digits short using:\n",
    "\n",
    "`df['FIPS']=df'FIPS'].apply(lambda x: '{0:0>5}'.format(x))`\n",
    "\n",
    "Too easier combine the different datasets, a dictionary of the states and their abbreviation (`us_state_to_abbrev`) is needed to translate the states. This allows us to use `pandas.groupby` to combine the states and counties. It is important to groupby both State and County since some county names may repeat across different States.\n",
    "\n",
    "A few rows also had floats represented as a string, which had to be translated into floats to analyse.\n",
    "\n",
    "### FastFood Chains across America\n",
    "The FastFood Dataset consists of 10000 rows and 14 columns. A row corresponds to a resturant in the US and the first columns consists of a address, the name of the Fastfood chain, the state etc. This dataset does not have a column for county, so we have to extract that information ourselves and create a new column to group this data together with the other datasets. Since the postalcode is a column in the dataset, we can use `pgeocode` to extract the county information for each resturant. \n",
    "\n",
    "```\n",
    "nomi = pgeocode.Nominatim('us')\n",
    "county_names = []\n",
    "for i in range(len(FastFood)):\n",
    "    county_names.append(nomi.query_postal_code(FastFood[\"postalCode\"][i]).county_name)\n",
    "    \n",
    "FastFood[\"County\"] = county_names\n",
    "```\n",
    "\n",
    "* Write a short section that discusses the dataset stats, containing key points/plots from your exploratory data analysis.\n",
    "## Dataset Stats\n",
    "\n",
    "\n",
    "THe initial \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b245740",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
